{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c832dce9",
   "metadata": {},
   "source": [
    "# Our data tends to look way worse... let's import a dataset with \"noise\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42704c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # This is to ignore any warnings that might pop up during execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "799d26be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic libraries to manipulate data\n",
    "import matplotlib.pyplot as plt  # Matplotlib for data visualization\n",
    "import numpy as np  # Numpy for numerical computations\n",
    "import pandas as pd  # Pandas for data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5630ebc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)  # To ensure all the probabilistic things are reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a28f26f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the datasets\n",
    "data_path = \"./data/\"\n",
    "\n",
    "# Specify the filenames of the datasets\n",
    "survey_filename = \"survey_music_noise.csv\"\n",
    "\n",
    "# Read the CSV files and create backup copies\n",
    "survey_df_data = pd.read_csv(data_path + survey_filename)\n",
    "\n",
    "# Create working copies of the dataframes for analysis\n",
    "survey_df = survey_df_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f727a8b3",
   "metadata": {},
   "source": [
    "Last time we saw how useful it was to get the correct dtype in a column because of the different functions are way more efficient and easy to define. \n",
    "In this notebook we will see all the different values of the columns that don't allow us to get a correct prediction, correct them and convert each column to the correct dtype. Then we will diagnose the problems with our dataset (a step called **Data Profiling**) in order to get a clean dataset in the next notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afc20bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 779 entries, 0 to 778\n",
      "Data columns (total 33 columns):\n",
      " #   Column                        Non-Null Count  Dtype \n",
      "---  ------                        --------------  ----- \n",
      " 0   Timestamp                     766 non-null    object\n",
      " 1   Age                           759 non-null    object\n",
      " 2   Primary streaming service     767 non-null    object\n",
      " 3   Hours per day                 765 non-null    object\n",
      " 4   While working                 769 non-null    object\n",
      " 5   Instrumentalist               761 non-null    object\n",
      " 6   Composer                      766 non-null    object\n",
      " 7   Fav genre                     765 non-null    object\n",
      " 8   Exploratory                   769 non-null    object\n",
      " 9   Foreign languages             755 non-null    object\n",
      " 10  BPM                           660 non-null    object\n",
      " 11  Frequency [Classical]         767 non-null    object\n",
      " 12  Frequency [Country]           764 non-null    object\n",
      " 13  Frequency [EDM]               763 non-null    object\n",
      " 14  Frequency [Folk]              770 non-null    object\n",
      " 15  Frequency [Gospel]            767 non-null    object\n",
      " 16  Frequency [Hip hop]           764 non-null    object\n",
      " 17  Frequency [Jazz]              762 non-null    object\n",
      " 18  Frequency [K pop]             768 non-null    object\n",
      " 19  Frequency [Latin]             765 non-null    object\n",
      " 20  Frequency [Lofi]              763 non-null    object\n",
      " 21  Frequency [Metal]             765 non-null    object\n",
      " 22  Frequency [Pop]               757 non-null    object\n",
      " 23  Frequency [R&B]               766 non-null    object\n",
      " 24  Frequency [Rap]               768 non-null    object\n",
      " 25  Frequency [Rock]              763 non-null    object\n",
      " 26  Frequency [Video game music]  769 non-null    object\n",
      " 27  Anxiety                       765 non-null    object\n",
      " 28  Depression                    762 non-null    object\n",
      " 29  Insomnia                      766 non-null    object\n",
      " 30  OCD                           768 non-null    object\n",
      " 31  Music effects                 755 non-null    object\n",
      " 32  Permissions                   767 non-null    object\n",
      "dtypes: object(33)\n",
      "memory usage: 201.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Let's check its structure\n",
    "survey_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c586ca",
   "metadata": {},
   "source": [
    "# Timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67782227",
   "metadata": {},
   "source": [
    "Since all of the columns appear as object we can access their str methods. This will help us see if the values are of the length we require"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7318da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.0    417\n",
       "17.0    284\n",
       "16.0     49\n",
       "NaN      13\n",
       "19.0     10\n",
       "1.0       3\n",
       "4.0       3\n",
       "Name: Timestamp, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the count for each component (including NA values)\n",
    "survey_df['Timestamp'].str.len().value_counts(dropna=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93bc19d",
   "metadata": {},
   "source": [
    "The records that have length less than 16 cannot be a true date. We will inspect these rows first obtaining a mask over the ones with length fewer than 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab85c399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79        0\n",
       "234    -500\n",
       "253       0\n",
       "345    -500\n",
       "603    Null\n",
       "765       0\n",
       "Name: Timestamp, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "less_than_16=survey_df['Timestamp'][survey_df['Timestamp'].\n",
    "                                    str.len()<16]\n",
    "less_than_16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7321b4",
   "metadata": {},
   "source": [
    "These are clearly null values so we substitute them into a None value which is more suited to denote a missing value in an object dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0836fa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_df['Timestamp'][survey_df['Timestamp'].str.len()<16]=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f663c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.0    417\n",
       "17.0    284\n",
       "16.0     49\n",
       "NaN      19\n",
       "19.0     10\n",
       "Name: Timestamp, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df['Timestamp'].str.len().value_counts(dropna=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ac8dc0",
   "metadata": {},
   "source": [
    "We'll try to convert it as it is now into a datetime dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3e4d53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.to_datetime(survey_df['Timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88d8b182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, '9/28/2022 17:25:48', '9/13/2022 16:16:16',\n",
       "       '9/10/2022 9:06:07', '8/29/2022 2:46:38', '8/28/2022 14:12:55',\n",
       "       '9/3/2022 17:14:57', '8/28/2022 11:08:51', '9/12/2022 18:10:24',\n",
       "       '8/29/2022 0:03:43', '8/29/2022 4:37:05', '8/28/2022 17:33:12',\n",
       "       '10/5/2022 12:30:23', '8/29/2022 10:44:43', '9/21/2022 21:12:20',\n",
       "       '8/28/2022 19:16:43', '8/28/2022 21:48:29', '9/1/2022 16:58:12',\n",
       "       '8/29/2022 18:22:58', '8/28/2022 12:54:35', '10/6/2022 3:35:11',\n",
       "       '9/15/2022 15:30:41', '8/29/2022 9:42:23', '8/29/2022 2:43:40',\n",
       "       '9/1/2022 15:21:55', '8/29/2022 1:34:27', '8/29/2022 6:58:24',\n",
       "       '8/28/2022 21:14:34', '8/28/2022 11:25:49', '10/4/2022 8:53:39',\n",
       "       '9/2/2022 14:09:04', '8/31/2022 9:42:46', '8/29/2022 19:07:50',\n",
       "       '8/31/2022 8:35:00', '8/28/2022 18:55:44', '9/1/2022 17:00:07',\n",
       "       '8/28/2022 18:35:17', '8/28/2022 15:22:00', '8/30/2022 16:04:47',\n",
       "       '8/29/2022 4:10:25', '8/29/2022 5:08:52', '8/28/2022 12:39:49',\n",
       "       '10/4/2022 14:50:28', '9/2/2022 1:03:00', '8/29/2022 16:39:08',\n",
       "       '8/29/2022 9:56:31', '8/27/2022 22:00:29', '9/7/2022 12:32:12',\n",
       "       '8/28/2022 21:11:09', '9/13/2022 1:57:14', '8/28/2022 20:57:16',\n",
       "       '8/28/2022 15:02:14', '8/29/2022 5:14:53', '8/29/2022 12:25:16',\n",
       "       '8/28/2022 18:58:09', '8/29/2022 3:29:44', '10/14/2022 18:01:12',\n",
       "       '8/28/2022 14:26:12', '8/28/2022 17:41:15', '8/28/2022 19:27:46',\n",
       "       '9/12/2022 18:09:18', '8/28/2022 18:56:54', '9/27/2022 13:32:27',\n",
       "       '9/23/2022 23:43:10', '9/2/2022 8:06:29', '8/28/2022 1:39:02',\n",
       "       '8/28/2022 13:46:03', '9/15/2022 9:41:28', '8/28/2022 21:55:05',\n",
       "       '8/28/2022 16:15:08', '9/12/2022 16:24:44', '9/13/2022 22:19:10',\n",
       "       '8/28/2022 10:54:30', '9/3/2022 5:27:15', '8/28/2022 13:22:36',\n",
       "       '8/28/2022 22:04:16', '9/12/2022 18:07:54', '9/4/2022 2:32:07',\n",
       "       '8/28/2022 22:38:36', '9/3/2022 16:24:38', '8/28/2022 16:30:36',\n",
       "       '9/1/2022 17:48:55', '9/6/2022 14:43:07', '9/1/2022 15:24:02',\n",
       "       '8/31/2022 16:47:03', '8/29/2022 20:03:04', '8/28/2022 16:23:43',\n",
       "       '8/29/2022 23:36:14', '8/29/2022 19:44:49', '9/13/2022 11:16:37',\n",
       "       '8/28/2022 18:08:44', '10/2/2022 7:52:02', '8/27/2022 23:16:06',\n",
       "       '8/28/2022 5:16:30', '8/28/2022 19:29:25', '9/2/2022 0:08:07',\n",
       "       '8/28/2022 13:05:46', '8/28/2022 10:30:22', '10/3/2022 20:03:57',\n",
       "       '8/29/2022 20:22:33', '8/28/2022 19:35:58', '8/28/2022 11:13:25',\n",
       "       '8/28/2022 12:37:17', '8/28/2022 22:39:58', '9/24/2022 0:42:39',\n",
       "       '8/31/2022 12:53:28', '8/28/2022 11:36:35', '9/9/2022 7:48:44',\n",
       "       '8/29/2022 9:26:07', '9/1/2022 15:01:10', '10/3/2022 10:53:28',\n",
       "       '9/12/2022 19:03:41', '8/28/2022 17:40:15', '8/28/2022 16:58:35',\n",
       "       '9/3/2022 21:52:02', '8/28/2022 22:39:24', '8/29/2022 9:43:35',\n",
       "       '8/29/2022 9:01:49', '8/29/2022 18:57:09', '8/28/2022 14:38:19',\n",
       "       '10/30/2022 13:15:26', '9/3/2022 10:41:32', '9/7/2022 14:17:21',\n",
       "       '8/28/2022 14:10:17', '8/28/2022 11:50:31', '8/28/2022 15:03:56',\n",
       "       '8/28/2022 19:30:49', '8/29/2022 5:41:25', '8/28/2022 20:57:57',\n",
       "       '8/29/2022 1:26:19', '8/29/2022 3:21:18', '9/6/2022 10:12:09',\n",
       "       '9/14/2022 9:56:39', '8/28/2022 18:53:03', '10/30/2022 14:37:28',\n",
       "       '9/7/2022 19:43:58', '8/29/2022 7:17:09', '10/4/2022 19:43:11',\n",
       "       '8/29/2022 5:06:50', '9/12/2022 20:07:14', '8/28/2022 14:24:10',\n",
       "       '8/29/2022 8:37:30', '9/1/2022 19:44:33', '8/28/2022 18:58:27',\n",
       "       '9/4/2022 20:38:17', '8/28/2022 12:30:08', '8/29/2022 8:38:53',\n",
       "       '8/29/2022 0:21:31', '8/30/2022 5:16:13', '9/1/2022 17:17:48',\n",
       "       '8/28/2022 19:12:02', '8/28/2022 11:39:21', '8/28/2022 19:18:53',\n",
       "       '9/1/2022 15:24:13', '8/29/2022 16:07:39', '8/28/2022 19:22:30',\n",
       "       '8/28/2022 3:19:08', '9/8/2022 19:16:43', '9/13/2022 9:29:29',\n",
       "       '8/28/2022 21:23:07', '8/29/2022 6:44:14', '9/4/2022 11:15:06',\n",
       "       '8/28/2022 14:47:08', '8/30/2022 0:00:29', '9/5/2022 2:08:46',\n",
       "       '8/28/2022 22:05:53', '8/29/2022 5:45:03', '8/28/2022 18:51:10',\n",
       "       '9/1/2022 19:39:07', '8/29/2022 16:05:19', '9/4/2022 9:22:58',\n",
       "       '9/12/2022 19:13:06', '8/29/2022 11:04:24', '9/12/2022 14:29:16',\n",
       "       '8/28/2022 14:30:34', '9/15/2022 11:09:46', '8/28/2022 20:37:41',\n",
       "       '8/28/2022 19:10:07', '8/28/2022 12:12:35', '8/29/2022 6:31:56',\n",
       "       '8/29/2022 10:41:11', '8/29/2022 10:45:36', '9/2/2022 6:41:49',\n",
       "       '9/2/2022 7:53:55', '9/3/2022 3:54:07', '9/3/2022 15:52:50',\n",
       "       '9/6/2022 11:15:37', '8/29/2022 3:46:02', '8/28/2022 13:43:06',\n",
       "       '8/29/2022 8:47:09', '8/28/2022 19:46:02', '8/29/2022 5:22:38',\n",
       "       '9/2/2022 6:20:43', '8/29/2022 7:52:49', '8/28/2022 20:14:02',\n",
       "       '9/3/2022 7:09:22', '9/19/2022 18:34:27', '9/4/2022 10:07:27',\n",
       "       '8/30/2022 16:47:39', '8/29/2022 20:47:47', '8/29/2022 8:28:46',\n",
       "       '8/28/2022 21:31:40', '8/28/2022 17:43:22', '8/28/2022 14:58:17',\n",
       "       '9/1/2022 14:56:21', '10/3/2022 13:01:06', '9/16/2022 21:55:32',\n",
       "       '8/28/2022 14:07:29', '9/5/2022 8:21:48', '8/31/2022 18:56:31',\n",
       "       '8/28/2022 13:48:11', '9/12/2022 12:46:55', '8/28/2022 22:53:43',\n",
       "       '8/29/2022 0:32:36', '8/28/2022 14:04:09', '8/28/2022 17:15:18',\n",
       "       '9/3/2022 14:35:13', '9/13/2022 7:06:03', '8/27/2022 19:57:31',\n",
       "       '8/28/2022 14:14:48', '9/5/2022 6:29:00', '9/4/2022 21:44:26',\n",
       "       '8/28/2022 10:38:05', '8/27/2022 22:33:05', '8/31/2022 15:48:18',\n",
       "       '8/29/2022 9:13:14', '8/29/2022 2:40:16', '11/4/2022 17:31:47',\n",
       "       '8/28/2022 11:27:15', '9/12/2022 22:26:06', '8/28/2022 22:21:12',\n",
       "       '8/29/2022 3:49:29', '9/2/2022 8:05:59', '8/29/2022 3:01:38',\n",
       "       '9/16/2022 1:47:01', '8/29/2022 10:23:22', '9/12/2022 12:15:54',\n",
       "       '8/29/2022 18:00:27', '8/29/2022 1:22:44', '8/28/2022 13:22:53',\n",
       "       '8/28/2022 10:59:53', '10/4/2022 4:50:49', '9/1/2022 13:14:34',\n",
       "       '9/23/2022 23:05:47', '9/12/2022 9:39:30', '8/28/2022 19:46:57',\n",
       "       '8/29/2022 20:03:00', '8/27/2022 23:19:52', '8/28/2022 22:06:46',\n",
       "       '8/30/2022 18:15:39', '8/28/2022 18:18:24', '8/28/2022 4:40:36',\n",
       "       '8/28/2022 19:04:26', '8/29/2022 4:02:01', '8/27/2022 23:43:06',\n",
       "       '8/29/2022 11:16:34', '9/12/2022 13:55:53', '9/6/2022 19:27:55',\n",
       "       '8/28/2022 17:14:08', '9/3/2022 14:08:20', '9/2/2022 7:13:38',\n",
       "       '8/29/2022 17:04:16', '8/28/2022 15:09:31', '9/4/2022 5:22:34',\n",
       "       '8/29/2022 7:11:40', '8/28/2022 16:32:40', '9/13/2022 1:55:43',\n",
       "       '9/2/2022 3:06:53', '9/2/2022 4:56:56', '8/28/2022 23:47:13',\n",
       "       '8/29/2022 2:28:45', '9/2/2022 3:32:55', '8/28/2022 11:55:54',\n",
       "       '8/28/2022 23:50:25', '10/30/2022 13:13:32', '8/27/2022 23:00:32',\n",
       "       '9/1/2022 13:13:06', '9/2/2022 7:29:17', '8/29/2022 0:33:49',\n",
       "       '9/12/2022 13:33:58', '8/28/2022 14:10:04', '9/2/2022 7:13:53',\n",
       "       '8/28/2022 17:32:18', '9/1/2022 17:27:50', '8/28/2022 20:12:05',\n",
       "       '8/30/2022 6:05:56', '8/30/2022 14:25:28', '9/13/2022 8:05:59',\n",
       "       '8/28/2022 18:17:00', '8/30/2022 11:12:36', '9/13/2022 13:18:32',\n",
       "       '8/28/2022 23:08:27', '9/1/2022 19:36:54', '10/4/2022 0:48:34',\n",
       "       '8/28/2022 12:53:01', '8/29/2022 3:14:38', '8/28/2022 16:37:10',\n",
       "       '8/29/2022 0:05:09', '8/28/2022 13:34:27', '9/2/2022 5:49:20',\n",
       "       '9/2/2022 14:31:06', '8/29/2022 10:25:54', '8/28/2022 14:25:08',\n",
       "       '8/27/2022 22:51:15', '8/29/2022 0:47:12', '8/28/2022 22:10:24',\n",
       "       '8/28/2022 12:23:52', '8/28/2022 16:30:17', '8/30/2022 17:33:13',\n",
       "       '8/28/2022 14:02:12', '9/3/2022 21:08:12', '8/28/2022 23:26:58',\n",
       "       '8-30-2022 0.14.35', '8/29/2022 2:06:14', '9/2/2022 16:36:02',\n",
       "       '8/28/2022 21:48:12', '8/28/2022 23:56:06', '8/28/2022 12:15:02',\n",
       "       '8/28/2022 13:55:45', '9/8/2022 21:30:13', '8/29/2022 19:08:34',\n",
       "       '9/12/2022 13:31:22', '9/9/2022 22:31:31', '10/11/2022 15:46:46',\n",
       "       '8/29/2022 6:13:47', '9/13/2022 7:12:07', '9/6/2022 13:26:11',\n",
       "       '8/27/2022 23:39:49', '8/28/2022 22:09:11', '8/29/2022 0:54:55',\n",
       "       '9/4/2022 21:29:06', '8/29/2022 4:53:44', '8/27/2022 21:28:18',\n",
       "       '8/28/2022 23:40:54', '8/29/2022 0:47:59', '9/2/2022 9:25:05',\n",
       "       '8/28/2022 18:28:48', '8/28/2022 20:20:52', '9/2/2022 5:40:14',\n",
       "       '8/29/2022 2:46:27', '8/28/2022 21:47:26', '8/29/2022 3:13:27',\n",
       "       '8/29/2022 14:13:58', '9/12/2022 15:12:27', '9/13/2022 4:45:33',\n",
       "       '8/29/2022 14:53:54', '8/29/2022 5:35:40', '9/6/2022 9:40:57',\n",
       "       '8/29/2022 15:18:16', '8/28/2022 21:30:41', '8/28/2022 21:03:23',\n",
       "       '10/4/2022 19:33:42', '8/28/2022 14:59:05', '9/1/2022 16:06:10',\n",
       "       '9/3/2022 18:01:31', '8/28/2022 16:07:28', '8/31/2022 1:39:16',\n",
       "       '9/1/2022 18:10:41', '8/28/2022 14:49:18', '8/27/2022 21:40:40',\n",
       "       '9/2/2022 16:14:44', '8/31/2022 20:40:05', '8/29/2022 9:47:21',\n",
       "       '8/28/2022 18:30:21', '8/28/2022 19:26:23', '8/29/2022 17:32:02',\n",
       "       '9/2/2022 19:39:37', '9/19/2022 20:09:43', '9/1/2022 18:11:35',\n",
       "       '8/28/2022 22:03:40', '8/29/2022 15:05:22', '9/1/2022 18:02:53',\n",
       "       '9/10/2022 6:07:56', '9/1/2022 15:50:14', '8/28/2022 22:14:30',\n",
       "       '10/3/2022 15:38:19', '8/29/2022 4:41:30', '8/28/2022 17:14:32',\n",
       "       '8/28/2022 15:32:38', '9/12/2022 18:54:01', '9/3/2022 18:37:51',\n",
       "       '8/28/2022 13:59:16', '8/29/2022 0:39:19', '8/28/2022 12:08:29',\n",
       "       '9/25/2022 14:01:57', '8/28/2022 18:57:39', '10/3/2022 9:30:19',\n",
       "       '9/6/2022 12:36:19', '8/29/2022 2:03:07', '8/28/2022 17:54:30',\n",
       "       '9/4/2022 15:41:59', '8/29/2022 0:05:36', '9/9/2022 11:15:23',\n",
       "       '8/28/2022 20:32:41', '9/8/2022 23:40:30', '8/29/2022 9:52:20',\n",
       "       '8/29/2022 2:25:53', '9/1/2022 15:36:18', '9/2/2022 4:56:02',\n",
       "       '8/29/2022 20:18:37', '9/10/2022 2:59:03', '9/2/2022 21:14:59',\n",
       "       '8/29/2022 3:09:21', '8/29/2022 5:37:56', '9/1/2022 12:04:47',\n",
       "       '9/4/2022 17:54:29', '8/30/2022 12:03:11', '8/29/2022 20:04:14',\n",
       "       '8/28/2022 17:19:10', '8/29/2022 4:42:51', '9/29/2022 17:54:15',\n",
       "       '8/28/2022 19:04:05', '9/28/2022 19:37:41', '9/12/2022 12:14:25',\n",
       "       '8/28/2022 13:42:20', '8/28/2022 12:32:09', '8/29/2022 11:41:34',\n",
       "       '8/29/2022 5:50:21', '9/2/2022 1:59:54', '8/29/2022 17:22:01',\n",
       "       '8/29/2022 4:57:35', '8/29/2022 23:20:48', '9/2/2022 19:20:33',\n",
       "       '9/1/2022 14:59:20', '8/31/2022 5:45:08', '8/28/2022 16:53:26',\n",
       "       '9/14/2022 0:09:08', '9/1/2022 18:38:46', '8/28/2022 15:07:16',\n",
       "       '8/29/2022 21:24:24', '8/29/2022 21:21:30', '9/1/2022 9:25:07',\n",
       "       '9-3-2022 13.52.38', '8/30/2022 11:05:06', '9/2/2022 9:54:23',\n",
       "       '9/13/2022 0:48:14', '8/27/2022 23:40:55', '8/29/2022 20:12:32',\n",
       "       '9/9/2022 7:19:08', '9/19/2022 23:53:37', '10/9/2022 22:15:59',\n",
       "       '8/29/2022 18:56:27', '10/3/2022 13:47:14', '9/2/2022 3:27:21',\n",
       "       '8/28/2022 23:34:19', '9/8/2022 18:12:17', '11/9/2022 1:55:20',\n",
       "       '8/28/2022 18:18:12', '9/3/2022 15:52:55', '9/1/2022 2:32:43',\n",
       "       '8/28/2022 13:09:53', '8/28/2022 20:50:37', '9/13/2022 13:58:18',\n",
       "       '8/27/2022 23:41:36', '9/3/2022 10:20:18', '9/3/2022 18:23:01',\n",
       "       '8/28/2022 4:38:14', '8/30/2022 10:10:44', '8/28/2022 21:52:44',\n",
       "       '9/13/2022 16:34:56', '8/29/2022 3:47:32', '9/27/2022 11:46:56',\n",
       "       '9/1/2022 16:30:33', '9/2/2022 21:19:33', '9/12/2022 23:09:28',\n",
       "       '8/28/2022 13:18:19', '10/3/2022 11:30:10', '8/28/2022 23:23:20',\n",
       "       '8/30/2022 6:10:58', '8/28/2022 22:58:10', '9/12/2022 14:44:24',\n",
       "       '9/9/2022 11:25:57', '8/29/2022 4:17:46', '9/4/2022 5:01:04',\n",
       "       '9/18/2022 16:23:29', '8/28/2022 22:51:30', '8/27/2022 23:12:03',\n",
       "       '8/29/2022 12:30:01', '9/6/2022 11:19:55', '8/29/2022 0:33:06',\n",
       "       '8/30/2022 17:43:36', '8/28/2022 14:08:57', '9/1/2022 21:14:09',\n",
       "       '10/26/2022 19:45:54', '8/28/2022 19:07:16', '8/28/2022 18:17:46',\n",
       "       '8/28/2022 18:06:24', '8/28/2022 14:41:04', '9/2/2022 0:20:40',\n",
       "       '8/27/2022 23:39:41', '9/12/2022 23:16:49', '8/28/2022 19:29:08',\n",
       "       '8/27/2022 22:18:59', '8/28/2022 21:24:10', '8/28/2022 0:28:02',\n",
       "       '8/28/2022 21:26:19', '8/29/2022 7:48:34', '8/29/2022 22:00:46',\n",
       "       '8/30/2022 16:43:28', '9/1/2022 19:39:49', '9/3/2022 12:26:29',\n",
       "       '8/29/2022 17:58:47', '10/30/2022 7:24:08', '8/29/2022 1:54:06',\n",
       "       '8/31/2022 14:28:33', '9/12/2022 13:46:34', '9/1/2022 21:07:33',\n",
       "       '9/1/2022 14:57:20', '8/31/2022 13:20:39', '8/31/2022 21:04:07',\n",
       "       '8/28/2022 16:08:12', '8/28/2022 8:36:27', '9/7/2022 21:19:11',\n",
       "       '9/1/2022 3:38:02', '9/2/2022 5:21:18', '8/28/2022 20:43:43',\n",
       "       '9/3/2022 8:53:08', '8/31/2022 18:56:39', '8/28/2022 13:01:42',\n",
       "       '8/29/2022 4:36:16', '9/18/2022 20:32:27', '9/7/2022 9:16:47',\n",
       "       '9/12/2022 19:41:23', '8/28/2022 21:06:09', '9/2/2022 0:32:48',\n",
       "       '9/24/2022 10:59:12', '8/28/2022 18:02:14', '8/28/2022 23:04:08',\n",
       "       '9/13/2022 8:36:33', '9/2/2022 15:24:02', '8/28/2022 14:45:44',\n",
       "       '9/4/2022 22:32:18', '8/29/2022 3:44:33', '9/24/2022 10:25:15',\n",
       "       '8/28/2022 16:15:39', '8/28/2022 13:57:47', '8/28/2022 4:13:11',\n",
       "       '8/29/2022 3:32:43', '9/8/2022 18:14:01', '9/27/2022 8:17:33',\n",
       "       '8/29/2022 2:54:06', '9/14/2022 0:58:57', '8/31/2022 23:09:44',\n",
       "       '9/1/2022 16:11:18', '8/31/2022 6:36:13', '9/13/2022 2:17:14',\n",
       "       '8/29/2022 16:28:12', '8/28/2022 23:23:41', '8/28/2022 17:27:12',\n",
       "       '8/29/2022 13:09:33', '8/28/2022 19:50:30', '8/28/2022 14:29:29',\n",
       "       '8/28/2022 17:37:42', '9/23/2022 23:06:29', '9/19/2022 9:37:09',\n",
       "       '8/31/2022 8:04:22', '8/29/2022 9:47:26', '8/28/2022 18:59:40',\n",
       "       '9/8/2022 15:06:09', '9/3/2022 20:49:52', '9/12/2022 14:20:17',\n",
       "       '9/10/2022 22:08:18', '8/28/2022 18:59:53', '8/29/2022 0:59:01',\n",
       "       '8/28/2022 16:15:58', '9/1/2022 15:26:35', '8/29/2022 2:22:37',\n",
       "       '8/28/2022 20:33:43', '8/27/2022 21:54:47', '8/28/2022 18:33:32',\n",
       "       '8/28/2022 21:30:33', '8/27/2022 22:44:03', '8/29/2022 11:02:29',\n",
       "       '8/29/2022 2:10:36', '8/28/2022 14:01:08', '9/2/2022 3:36:18',\n",
       "       '8/28/2022 23:34:37', '9/5/2022 12:10:54', '10/3/2022 16:43:32',\n",
       "       '9/2/2022 22:18:57', '8/29/2022 15:20:35', '9/6/2022 15:53:44',\n",
       "       '11/1/2022 22:26:42', '9/22/2022 12:32:45', '8/28/2022 17:56:27',\n",
       "       '9/1/2022 20:02:19', '8/29/2022 14:25:08', '9/1/2022 16:38:05',\n",
       "       '9/1/2022 15:05:15', '9/1/2022 1:16:46', '8/28/2022 21:28:30',\n",
       "       '8/29/2022 10:23:46', '8/28/2022 23:42:24', '8/28/2022 20:01:29',\n",
       "       '8/28/2022 14:18:22', '9/1/2022 21:05:57', '8/28/2022 22:13:00',\n",
       "       '8/28/2022 16:04:58', '8/29/2022 2:30:45', '9/4/2022 16:26:26',\n",
       "       '9/23/2022 21:07:24', '8/29/2022 0:50:27', '9/2/2022 4:06:21',\n",
       "       '8/29/2022 3:17:19', '8/28/2022 21:54:05', '9/5/2022 21:56:50',\n",
       "       '8/28/2022 23:19:35', '9/22/2022 15:03:22', '8/29/2022 2:49:37',\n",
       "       '8/28/2022 16:34:03', '9/3/2022 16:00:31', '8/28/2022 5:05:51',\n",
       "       '8/28/2022 19:56:46', '8/28/2022 18:18:18', '9/14/2022 7:07:15',\n",
       "       '8/28/2022 15:41:56', '8/28/2022 13:34:00', '9/1/2022 5:01:52',\n",
       "       '8/28/2022 16:27:00', '8/28/2022 18:21:19', '9/14/2022 12:44:04',\n",
       "       '8/29/2022 14:49:56', '8/28/2022 22:11:31', '8/28/2022 22:32:47',\n",
       "       '9/1/2022 22:38:20', '8/28/2022 20:20:20', '9/1/2022 20:36:10',\n",
       "       '9/12/2022 11:45:04', '8/29/2022 8:39:19', '8/29/2022 18:47:22',\n",
       "       '9/4/2022 13:07:45', '8/29/2022 22:52:14', '8/30/2022 14:43:14',\n",
       "       '9/2/2022 2:19:59', '8/30/2022 8:00:32', '9/19/2022 8:12:47',\n",
       "       '10/22/2022 15:20:29', '9/12/2022 12:09:32', '8/28/2022 18:03:27',\n",
       "       '8/28/2022 11:54:45', '8/28/2022 22:30:17', '8/28/2022 16:07:51',\n",
       "       '8/29/2022 5:20:21', '8/29/2022 0:50:03', '8-28-2022 20.14.47',\n",
       "       '9/15/2022 0:33:58', '10/23/2022 20:50:27', '8/28/2022 18:03:50',\n",
       "       '8/29/2022 0:39:59', '8/28/2022 15:03:51', '8/28/2022 11:58:48',\n",
       "       '8/27/2022 19:29:02', '8/29/2022 12:32:30', '9/13/2022 5:57:53',\n",
       "       '8/30/2022 9:35:28', '8/29/2022 17:52:06', '9/1/2022 16:35:30',\n",
       "       '9/4/2022 10:48:55', '9/1/2022 17:33:02', '8/29/2022 11:56:17',\n",
       "       '8/28/2022 19:40:03', '8/28/2022 21:01:18', '8/28/2022 18:13:47',\n",
       "       '9/12/2022 15:07:48', '9/1/2022 16:00:05', '9/4/2022 11:25:54',\n",
       "       '9/12/2022 14:27:43', '9/13/2022 23:06:06', '9/9/2022 18:44:18',\n",
       "       '8/28/2022 19:20:03', '8/29/2022 8:23:46', '8/28/2022 14:51:02',\n",
       "       '8/28/2022 22:51:01', '9/1/2022 21:44:49', '8/27/2022 23:04:00',\n",
       "       '8/29/2022 2:29:08', '8/29/2022 1:06:46', '10/3/2022 10:00:01',\n",
       "       '9/1/2022 16:38:12', '8/28/2022 18:54:47', '9/1/2022 21:24:34',\n",
       "       '8/28/2022 22:14:01', '9/1/2022 16:43:48', '8/29/2022 4:51:37',\n",
       "       '10/14/2022 20:42:26', '9/23/2022 23:06:12', '8/29/2022 1:59:22',\n",
       "       '8/28/2022 16:13:28', '8/29/2022 6:00:25', '8/28/2022 13:08:24',\n",
       "       '8/29/2022 1:17:44', '9/1/2022 17:51:31', '8/29/2022 7:53:58',\n",
       "       '10/5/2022 8:58:16', '9/1/2022 23:11:19', '8/29/2022 1:34:06',\n",
       "       '9/12/2022 14:42:44', '9/12/2022 22:24:29', '9/3/2022 20:58:21',\n",
       "       '9/2/2022 9:15:48', '8/29/2022 18:13:51', '8/29/2022 17:36:01',\n",
       "       '9/1/2022 19:09:32', '9/8/2022 16:56:15', '10/15/2022 14:00:55',\n",
       "       '8/29/2022 2:30:08', '8/28/2022 17:15:27', '8/29/2022 9:07:42',\n",
       "       '8/29/2022 4:02:12', '10/3/2022 10:25:46', '8/28/2022 23:54:34',\n",
       "       '8/28/2022 19:30:42', '8/28/2022 14:04:20', '8/29/2022 18:09:17',\n",
       "       '8/28/2022 21:14:51', '8/27/2022 21:56:50', '8/28/2022 19:59:01',\n",
       "       '8/28/2022 14:00:18', '8/28/2022 23:23:50', '10/4/2022 8:12:33',\n",
       "       '10/6/2022 9:17:46', '9/9/2022 23:34:31', '8/29/2022 22:04:50',\n",
       "       '8/28/2022 22:49:17', '9/12/2022 23:56:16', '8/30/2022 1:01:09',\n",
       "       '9/1/2022 5:20:01', '11/3/2022 23:24:38', '8/28/2022 12:52:19',\n",
       "       '8/28/2022 21:55:22', '8/28/2022 16:37:00', '8/30/2022 13:07:20',\n",
       "       '8/28/2022 20:15:28', '9/1/2022 19:08:55', '8/28/2022 20:04:49',\n",
       "       '9/16/2022 9:24:53'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df['Timestamp'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4202bcd",
   "metadata": {},
   "source": [
    "The error is informative since it shows we have data of the type \"8-30-2022 0.14.35\" while al the data we had seen had a format of days separated from months and years with a / and hour, minute and second separated with :\n",
    "\n",
    "We will replace each of these symbols using the replace method of the str accessor we've previously reviewed. This function takes a pattern to replace and then what its going to be replaced by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8a8f979",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_df['Timestamp']=survey_df['Timestamp'].str.replace('.',':')\n",
    "survey_df['Timestamp']=survey_df['Timestamp'].str.replace('-','/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a8f3f5",
   "metadata": {},
   "source": [
    "With these substitutions we can finally convert it into a datetime dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5dd1a4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 779 entries, 0 to 778\n",
      "Data columns (total 33 columns):\n",
      " #   Column                        Non-Null Count  Dtype         \n",
      "---  ------                        --------------  -----         \n",
      " 0   Timestamp                     760 non-null    datetime64[ns]\n",
      " 1   Age                           759 non-null    object        \n",
      " 2   Primary streaming service     767 non-null    object        \n",
      " 3   Hours per day                 765 non-null    object        \n",
      " 4   While working                 769 non-null    object        \n",
      " 5   Instrumentalist               761 non-null    object        \n",
      " 6   Composer                      766 non-null    object        \n",
      " 7   Fav genre                     765 non-null    object        \n",
      " 8   Exploratory                   769 non-null    object        \n",
      " 9   Foreign languages             755 non-null    object        \n",
      " 10  BPM                           660 non-null    object        \n",
      " 11  Frequency [Classical]         767 non-null    object        \n",
      " 12  Frequency [Country]           764 non-null    object        \n",
      " 13  Frequency [EDM]               763 non-null    object        \n",
      " 14  Frequency [Folk]              770 non-null    object        \n",
      " 15  Frequency [Gospel]            767 non-null    object        \n",
      " 16  Frequency [Hip hop]           764 non-null    object        \n",
      " 17  Frequency [Jazz]              762 non-null    object        \n",
      " 18  Frequency [K pop]             768 non-null    object        \n",
      " 19  Frequency [Latin]             765 non-null    object        \n",
      " 20  Frequency [Lofi]              763 non-null    object        \n",
      " 21  Frequency [Metal]             765 non-null    object        \n",
      " 22  Frequency [Pop]               757 non-null    object        \n",
      " 23  Frequency [R&B]               766 non-null    object        \n",
      " 24  Frequency [Rap]               768 non-null    object        \n",
      " 25  Frequency [Rock]              763 non-null    object        \n",
      " 26  Frequency [Video game music]  769 non-null    object        \n",
      " 27  Anxiety                       765 non-null    object        \n",
      " 28  Depression                    762 non-null    object        \n",
      " 29  Insomnia                      766 non-null    object        \n",
      " 30  OCD                           768 non-null    object        \n",
      " 31  Music effects                 755 non-null    object        \n",
      " 32  Permissions                   767 non-null    object        \n",
      "dtypes: datetime64[ns](1), object(32)\n",
      "memory usage: 201.0+ KB\n"
     ]
    }
   ],
   "source": [
    "survey_df['Timestamp']=pd.to_datetime(survey_df['Timestamp'])\n",
    "survey_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd96543",
   "metadata": {},
   "source": [
    "With these dtype we can make operations more suited to datetime like obtaining the month out of the date. To use these methods we have to use the `.dt` accessor, similar to the `.str` accesor we used before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe908814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      NaN\n",
       "1      9.0\n",
       "2      9.0\n",
       "3      9.0\n",
       "4      8.0\n",
       "      ... \n",
       "774    8.0\n",
       "775    8.0\n",
       "776    9.0\n",
       "777    8.0\n",
       "778    9.0\n",
       "Name: Timestamp, Length: 779, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df['Timestamp'].dt.month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f096e4",
   "metadata": {},
   "source": [
    "We have to do this for each column. And we can follow a similar strategy to the one above.\n",
    "\n",
    "To see an output of all of the values that cannot be converted into a certain dtype we will need to create our own function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b55516",
   "metadata": {},
   "source": [
    "# Numeric columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2fa842",
   "metadata": {},
   "source": [
    "## Age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890e1c75",
   "metadata": {},
   "source": [
    "Let's define a custom function that helps us see which values cannot be converted into floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "687aa1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Null', 'fifteen', 'twenty'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_non_convertible_floats(series):\n",
    "\n",
    "    non_convertibles = set()\n",
    "    for item in series:\n",
    "        try:\n",
    "            float(item)  # Try converting to float\n",
    "        except ValueError:\n",
    "            non_convertibles.add(item)  # Add to set if conversion fails\n",
    "    return non_convertibles\n",
    "\n",
    "find_non_convertible_floats(survey_df['Age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe366801",
   "metadata": {},
   "source": [
    "Now we see that the 'Null' value should be converted into a np.nan, and both the values fifteen and twenty should be replace with their numerical values. We can accomplish this with a replace dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "faca7de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_dict_numeric={'Null':np.nan,'fifteen':15,'twenty':20}\n",
    "\n",
    "survey_df['Age']=survey_df['Age'].replace(replace_dict_numeric)\n",
    "\n",
    "# Now we can convert it to the correct dtype\n",
    "survey_df['Age']=survey_df['Age'].astype(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa94736",
   "metadata": {},
   "source": [
    "## BPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "935018ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Null'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_non_convertible_floats(survey_df['BPM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8df8821",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_df['BPM']=survey_df['BPM'].replace(replace_dict_numeric)\n",
    "\n",
    "# Now we can convert it to the correct dtype\n",
    "survey_df['BPM']=survey_df['BPM'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063f150b",
   "metadata": {},
   "source": [
    "## Hours per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc7c31cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Null'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_non_convertible_floats(survey_df['Hours per day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52077f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_df['Hours per day']=survey_df['Hours per day'].replace(replace_dict_numeric)\n",
    "\n",
    "# Now we can convert it to the correct dtype\n",
    "survey_df['Hours per day']=survey_df['Hours per day'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d149cb2",
   "metadata": {},
   "source": [
    "## Mental health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0eac52fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Null'}\n",
      "{'Null'}\n",
      "{'Null'}\n",
      "{'Null'}\n"
     ]
    }
   ],
   "source": [
    "for col in ['Anxiety','Depression','Insomnia','OCD']:\n",
    "    print(find_non_convertible_floats(survey_df[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dac48ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['Anxiety','Depression','Insomnia','OCD']:\n",
    "    survey_df[col]=survey_df[col].replace(replace_dict_numeric)\n",
    "\n",
    "    # Now we can convert it to the correct dtype\n",
    "    survey_df[col]=survey_df[col].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f96a02ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 779 entries, 0 to 778\n",
      "Data columns (total 33 columns):\n",
      " #   Column                        Non-Null Count  Dtype         \n",
      "---  ------                        --------------  -----         \n",
      " 0   Timestamp                     760 non-null    datetime64[ns]\n",
      " 1   Age                           758 non-null    float64       \n",
      " 2   Primary streaming service     767 non-null    object        \n",
      " 3   Hours per day                 763 non-null    float64       \n",
      " 4   While working                 769 non-null    object        \n",
      " 5   Instrumentalist               761 non-null    object        \n",
      " 6   Composer                      766 non-null    object        \n",
      " 7   Fav genre                     765 non-null    object        \n",
      " 8   Exploratory                   769 non-null    object        \n",
      " 9   Foreign languages             755 non-null    object        \n",
      " 10  BPM                           659 non-null    float64       \n",
      " 11  Frequency [Classical]         767 non-null    object        \n",
      " 12  Frequency [Country]           764 non-null    object        \n",
      " 13  Frequency [EDM]               763 non-null    object        \n",
      " 14  Frequency [Folk]              770 non-null    object        \n",
      " 15  Frequency [Gospel]            767 non-null    object        \n",
      " 16  Frequency [Hip hop]           764 non-null    object        \n",
      " 17  Frequency [Jazz]              762 non-null    object        \n",
      " 18  Frequency [K pop]             768 non-null    object        \n",
      " 19  Frequency [Latin]             765 non-null    object        \n",
      " 20  Frequency [Lofi]              763 non-null    object        \n",
      " 21  Frequency [Metal]             765 non-null    object        \n",
      " 22  Frequency [Pop]               757 non-null    object        \n",
      " 23  Frequency [R&B]               766 non-null    object        \n",
      " 24  Frequency [Rap]               768 non-null    object        \n",
      " 25  Frequency [Rock]              763 non-null    object        \n",
      " 26  Frequency [Video game music]  769 non-null    object        \n",
      " 27  Anxiety                       764 non-null    float64       \n",
      " 28  Depression                    760 non-null    float64       \n",
      " 29  Insomnia                      764 non-null    float64       \n",
      " 30  OCD                           762 non-null    float64       \n",
      " 31  Music effects                 755 non-null    object        \n",
      " 32  Permissions                   767 non-null    object        \n",
      "dtypes: datetime64[ns](1), float64(7), object(25)\n",
      "memory usage: 201.0+ KB\n"
     ]
    }
   ],
   "source": [
    "survey_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725da315",
   "metadata": {},
   "source": [
    "# Categorical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5093bed0",
   "metadata": {},
   "source": [
    "We can see there are some columns that should be categorical, i.e. they can only take one value of a certain set of fixed values and they don't have any order between them (one isn't better than any other).\n",
    "\n",
    "To see this, the best way is to see a value counts on each categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7f38089",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Spotify                              471\n",
       "YouTube Music                         96\n",
       "I do not use a streaming service.     72\n",
       "Apple Music                           51\n",
       "Other streaming service               50\n",
       "NaN                                   12\n",
       "Pandora                               11\n",
       "0                                      6\n",
       "-500                                   2\n",
       "Null                                   2\n",
       "spotify                                1\n",
       "YOUTUBE MUSIC                          1\n",
       "other streaming service                1\n",
       "SPOTIFY                                1\n",
       "OTHER STREAMING SERVICE                1\n",
       " Spotify                               1\n",
       "Name: Primary streaming service, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df['Primary streaming service'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9303b9",
   "metadata": {},
   "source": [
    "As we can see we have some values that are the same except they're capitalized differently. For example we have `Spotify, spotify, SPOTIFY`. \n",
    "\n",
    "And we also have some null values that take on the same kind of placeholders as before: `-500,Null,0`. \n",
    "\n",
    "The second problem we already know how to fix: With a replace dictionary. For the first one we will put all the strings into lowercase and remove any spaces at the end of the word with the function `strip` "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
